{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD\n",
      "LTC-USD\n",
      "BCH-USD\n",
      "ETH-USD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_close</th>\n",
       "      <th>BTC-USD_volume</th>\n",
       "      <th>LTC-USD_close</th>\n",
       "      <th>LTC-USD_volume</th>\n",
       "      <th>BCH-USD_close</th>\n",
       "      <th>BCH-USD_volume</th>\n",
       "      <th>ETH-USD_close</th>\n",
       "      <th>ETH-USD_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1535214660</th>\n",
       "      <td>6707.799805</td>\n",
       "      <td>1.780853</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>51.901546</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>1.182528</td>\n",
       "      <td>279.089996</td>\n",
       "      <td>5.992979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214720</th>\n",
       "      <td>6708.100098</td>\n",
       "      <td>1.401337</td>\n",
       "      <td>58.009998</td>\n",
       "      <td>31.331142</td>\n",
       "      <td>531.469971</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>279.299988</td>\n",
       "      <td>12.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214780</th>\n",
       "      <td>6708.379883</td>\n",
       "      <td>0.975295</td>\n",
       "      <td>58.009998</td>\n",
       "      <td>14.458084</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>279.299988</td>\n",
       "      <td>6.183691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214840</th>\n",
       "      <td>6710.089844</td>\n",
       "      <td>1.293573</td>\n",
       "      <td>58.009998</td>\n",
       "      <td>93.464951</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>279.290009</td>\n",
       "      <td>4.150405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214900</th>\n",
       "      <td>6712.990234</td>\n",
       "      <td>2.330975</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>0.823356</td>\n",
       "      <td>531.469971</td>\n",
       "      <td>1.761348</td>\n",
       "      <td>279.299988</td>\n",
       "      <td>5.566861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214960</th>\n",
       "      <td>6713.140137</td>\n",
       "      <td>0.769891</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>6.434783</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>1.208560</td>\n",
       "      <td>279.359985</td>\n",
       "      <td>11.280577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215020</th>\n",
       "      <td>6714.520020</td>\n",
       "      <td>1.002652</td>\n",
       "      <td>58.009998</td>\n",
       "      <td>7.301921</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>279.359985</td>\n",
       "      <td>8.790519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215080</th>\n",
       "      <td>6714.520020</td>\n",
       "      <td>1.021925</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>23.802017</td>\n",
       "      <td>531.469971</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>279.369995</td>\n",
       "      <td>1.311763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215140</th>\n",
       "      <td>6715.000000</td>\n",
       "      <td>3.645508</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>6.953497</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>279.660004</td>\n",
       "      <td>11.752819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215200</th>\n",
       "      <td>6715.000000</td>\n",
       "      <td>0.513560</td>\n",
       "      <td>58.080002</td>\n",
       "      <td>202.403183</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.299520</td>\n",
       "      <td>279.649994</td>\n",
       "      <td>8.351710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
       "time                                                                       \n",
       "1535214660    6707.799805        1.780853      58.000000       51.901546   \n",
       "1535214720    6708.100098        1.401337      58.009998       31.331142   \n",
       "1535214780    6708.379883        0.975295      58.009998       14.458084   \n",
       "1535214840    6710.089844        1.293573      58.009998       93.464951   \n",
       "1535214900    6712.990234        2.330975      58.020000        0.823356   \n",
       "1535214960    6713.140137        0.769891      58.020000        6.434783   \n",
       "1535215020    6714.520020        1.002652      58.009998        7.301921   \n",
       "1535215080    6714.520020        1.021925      58.020000       23.802017   \n",
       "1535215140    6715.000000        3.645508      58.020000        6.953497   \n",
       "1535215200    6715.000000        0.513560      58.080002      202.403183   \n",
       "\n",
       "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \n",
       "time                                                                      \n",
       "1535214660     531.479980        1.182528     279.089996        5.992979  \n",
       "1535214720     531.469971        0.018900     279.299988       12.388200  \n",
       "1535214780     531.479980        0.100199     279.299988        6.183691  \n",
       "1535214840     531.479980        0.044015     279.290009        4.150405  \n",
       "1535214900     531.469971        1.761348     279.299988        5.566861  \n",
       "1535214960     531.479980        1.208560     279.359985       11.280577  \n",
       "1535215020     531.479980        0.016868     279.359985        8.790519  \n",
       "1535215080     531.469971        0.013854     279.369995        1.311763  \n",
       "1535215140     531.479980        0.016900     279.660004       11.752819  \n",
       "1535215200     531.479980        0.299520     279.649994        8.351710  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "SQC_LEN=60 #la longueur d'une séquence est d'une minute \n",
    "FUTURE_PERIOD_PRED = 3 #Prédire le prix aprés 3 min \n",
    "FUTURE_RATIO_PRED = \"ETH-USD\"\n",
    "\n",
    "\n",
    "\n",
    "main_df = pd.DataFrame() # begin empty\n",
    "fichiers=[\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"] \n",
    "\n",
    "for file in fichiers: \n",
    "    print(file)\n",
    "    \n",
    "    dataset =\"crypto_data/crypto_data/{}.csv\".format(file)  # get the full path to the file.\n",
    "    ?pd.read_csv\n",
    "    df=pd.read_csv(dataset,names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "    # rename volume and close \n",
    "    df.rename(columns={\"close\": \"{}_close\".format(file), \"volume\": \"{}_volume\".format(file)}, inplace=True)   \n",
    "    #print(df.head())\n",
    "    df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    df = df[[\"{}_close\".format(file), \"{}_volume\".format(file)]]  # ignorer  tous sauf le volume et the close \n",
    "\n",
    "    if len(main_df)==0: \n",
    "        main_df=df\n",
    "    else : \n",
    "        main_df=main_df.join(df)\n",
    "        \n",
    "        \n",
    "main_df.fillna(method=\"ffill\", inplace=True) #si il ya des valeurs flou  utiliser s'eux d'auparavant ! \n",
    "main_df.dropna(inplace=True) #pour supprimer les valeurs manquantes\n",
    "\n",
    "\n",
    "main_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant il nous faut une fonction  qui nous dit si c 'est un achat ou une vente \n",
    "pour identifier les classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1534643040    6371.009766        1.539134      56.889999       57.140900   \n",
      "1534643100    6371.009766        0.765422      56.919998        0.157505   \n",
      "1534643160    6371.009766        1.459322      56.919998        0.157505   \n",
      "1534643220    6370.009766        0.281895      56.919998        8.008989   \n",
      "1534643280    6370.000000        2.610539      56.910000       13.368497   \n",
      "1534643340    6370.009766        0.576384      56.910000       43.449566   \n",
      "1534643400    6370.000000        2.011349      56.919998        6.114026   \n",
      "1534643460    6365.200195        4.101097      56.910000        3.585331   \n",
      "1534643520    6360.160156        8.866956      56.919998       10.954050   \n",
      "1534643580    6360.160156        2.431280      56.919998        7.788442   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \\\n",
      "time                                                                       \n",
      "1534643040     549.530029        0.014485     293.489990      107.369453   \n",
      "1534643100     549.530029        0.949142     293.480011        4.742518   \n",
      "1534643160     549.530029        0.932551     293.489990       62.755810   \n",
      "1534643220     549.520020        1.776472     293.320007       48.176060   \n",
      "1534643280     549.000000        2.010557     293.429993        3.544814   \n",
      "1534643340     549.530029        2.589804     293.429993       21.671759   \n",
      "1534643400     550.049988       11.308352     293.429993       21.671759   \n",
      "1534643460     550.049988        1.098231     293.420013        1.275767   \n",
      "1534643520     549.460022        3.541107     293.190002       33.185760   \n",
      "1534643580     549.010010        0.738148     291.899994      253.679001   \n",
      "\n",
      "                future  Cible  \n",
      "time                           \n",
      "1534643040  293.320007      0  \n",
      "1534643100  293.429993      0  \n",
      "1534643160  293.429993      0  \n",
      "1534643220  293.429993      1  \n",
      "1534643280  293.420013      0  \n",
      "1534643340  293.190002      0  \n",
      "1534643400  291.899994      0  \n",
      "1534643460  291.309998      0  \n",
      "1534643520  291.309998      0  \n",
      "1534643580  290.440002      0  \n",
      "            ETH-USD_close      future  Cible\n",
      "time                                        \n",
      "1534643040     293.489990  293.320007      0\n",
      "1534643100     293.480011  293.429993      0\n",
      "1534643160     293.489990  293.429993      0\n",
      "1534643220     293.320007  293.429993      1\n",
      "1534643280     293.429993  293.420013      0\n",
      "1534643340     293.429993  293.190002      0\n",
      "1534643400     293.429993  291.899994      0\n",
      "1534643460     293.420013         NaN      0\n",
      "1534643520     293.190002         NaN      0\n",
      "1534643580     291.899994         NaN      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRIUMPHAL\\AppData\\Local\\conda\\conda\\envs\\TensorProject\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\TRIUMPHAL\\AppData\\Local\\conda\\conda\\envs\\TensorProject\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def classify(future,current):\n",
    "    if float(future) > float(current):\n",
    "        return 1 #si 1 Achat sinon vente \n",
    "    else : \n",
    "        return 0 \n",
    "\n",
    "#définissant maintenant notre colonne future ! \n",
    "print(main_df.tail(10))\n",
    "main_df[\"future\"]=main_df[\"{}_close\".format(FUTURE_RATIO_PRED)].shift(-FUTURE_PERIOD_PRED)#shift vas faire un décalage de 3 ligne dans la colonne close\n",
    "\n",
    "#mappons maintenant notre fonction sur la table en utilisant map qui prends en arguments  : la fonction puis ses parametres\n",
    "#ensuites le resultat doit etre une list en utilisant List()\n",
    "\n",
    "main_df[\"Cible\"]=list(map(classify,main_df[\"future\"],main_df[\"{}_close\".format(FUTURE_RATIO_PRED)])) \n",
    "print(main_df[[\"{}_close\".format(FUTURE_RATIO_PRED),\"future\",\"Cible\"]].tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il y a un problem ! vu que nos données sont different les montant surtt on doit les normaliser ! et donc maintenant il est temps de les normaliser alons y !\n",
    "il faut aussi les rendre equilibré ! \n",
    "mais avant nous devant séparé notre données au lieu de les mélanger car sa n'aura aucun sens ! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data \n",
      "            ETH-USD_close     future  Cible\n",
      "time                                       \n",
      "1528968720      486.01001  486.00000      0\n",
      "1528968780      486.00000  486.00000      0\n",
      "1528968840      485.75000  485.98999      1\n",
      "1528968900      486.00000  485.98999      0\n",
      "1528968960      486.00000  485.98999      0\n",
      "1528969020      485.98999  485.98999      0\n",
      "1528969080      485.98999  486.00000      1\n",
      "1528969140      485.98999  486.00000      1\n",
      "1528969200      485.98999  486.00000      1\n",
      "1528969260      486.00000  486.00000      0\n",
      "Validation data \n",
      "            ETH-USD_close      future  Cible\n",
      "time                                        \n",
      "1534643640     291.309998  291.559998      1\n",
      "1534643700     291.309998  291.559998      1\n",
      "1534643760     290.440002  291.570007      1\n",
      "1534643820     291.559998  291.359985      0\n",
      "1534643880     291.559998  291.519989      0\n",
      "1534643940     291.570007  291.429993      0\n",
      "1534644000     291.359985  291.429993      1\n",
      "1534644060     291.519989  291.429993      0\n",
      "1534644120     291.429993  291.429993      0\n",
      "1534644180     291.429993  291.450012      1\n"
     ]
    }
   ],
   "source": [
    "#Séparation test et train data !\n",
    "#trie croissant du temps ! \n",
    "times= sorted(main_df.index.values)#values nous donne une liste \n",
    "last_5pot=times[-int(0.05*len(times))]#last 5% du temps \n",
    "\n",
    "#séparation! \n",
    "validation_main_df=main_df[(main_df.index >= last_5pot)]#5%\n",
    "main_df= main_df[(main_df.index < last_5pot)]#majorité 95% de notre data \n",
    "\n",
    "\n",
    "print(\"Training data \")\n",
    "print(main_df[[\"{}_close\".format(FUTURE_RATIO_PRED),\"future\",\"Cible\"]].head(10))\n",
    "print(\"Validation data \")\n",
    "print(validation_main_df[[\"{}_close\".format(FUTURE_RATIO_PRED),\"future\",\"Cible\"]].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maint nous allons pouvoir faire  : la mise en échelle , la normalisation ,\n",
    "# de  nos données avce la fonction modify_df\n",
    "\n",
    "#sklearn est une librairie de machine learning qui propose des regressions , clustering ...\n",
    "from sklearn import preprocessing\n",
    "from collections import deque #deque est une fille doublement chainé avec une taille fixe ! qui peut etre donner avec le parametre maxlen \n",
    "import numpy as np \n",
    "import random \n",
    "\n",
    "\n",
    "def modify_df(df):\n",
    "    #elimination de la colonne future  vu qu'il y a rien à modifier dans celle ci \n",
    "    df=df.drop(\"future\",1)#1 veux dire colonne \n",
    "    for col in df.columns : \n",
    "        if col!=\"Cible\":\n",
    "            #on vas scaller tous sauf la Cible qui est soit 1 soit 0\n",
    "            #Percentage change between the current and a prior element.\n",
    "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
    "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1 Centrer à la moyenne et composante par composante à la variance d'unité. pour les normaliser ! \n",
    "    \n",
    "    df.dropna(inplace=True)  # cleanup again... jic. Those nasty NaNs love to creep in.\n",
    "    #print(df)\n",
    "    #Créant maintenant nos séquences ! \n",
    "    sequential_data= []\n",
    "    prev_days=deque(maxlen=SQC_LEN)#ceci veut dire que  la taillle amx de notre deque est 60 ! et donc les valeurs ancienne sont supprimer ! \n",
    "    \n",
    "    for i in df.values:  # iterate over the values ( une liste de liste )\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target \n",
    "        #pour chaque élement de df.values tous les valeurs apar le dernier  !  -1 c est le dernier ! Cible ! \n",
    "        \n",
    "        if len(prev_days) == SQC_LEN:  # make sure we have 60 secondes!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # i[-1] la cible de notre élement \n",
    "\n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "    \n",
    "    #balance the sequential data ! \n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  #parcour de la séquence pour séparer les achats et vente \n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "    #balancer les données ! \n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # rassembler les 2 \n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    #séparer the x_test and y_test \n",
    "    X = []\n",
    "    y = []\n",
    "    #Séparer les inputs et outputs \n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X), y  # return X and y...and make X a numpy array!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dropout,Dense,LSTM, CuDNNLSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint#ModelCheckpoint permet de sauvgarder des \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "#points importants et les suivre par exemple le max de la valeur de accuracy \n",
    "import time \n",
    "\n",
    "SQC_LEN=60 #la longueur d'une séquence est d'une minute \n",
    "FUTURE_PERIOD_PRED = 3 #Prédire le prix aprés 3 min \n",
    "FUTURE_RATIO_PRED = \"ETH-USD\"\n",
    "\n",
    "x_train,y_train=modify_df(main_df)\n",
    "x_val,y_val = modify_df(validation_main_df)\n",
    "\n",
    "\n",
    "#quelque constantes utiles \n",
    "#le nombre d'iterations : \n",
    "EPOCHS=6\n",
    "#BATCH SIZE \n",
    "BATCH_SIZE=64\n",
    "#NAME  for our tensorBoard et aussi pour l'enrengister aprés \n",
    "NAME = \"{}-SEQ-{}-PRED-{}\".format(FUTURE_RATIO_PRED,SQC_LEN,FUTURE_PERIOD_PRED,int(time.time()))  # a unique name for the model \n",
    "\n",
    "#définition des couches : \n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "couche_1=LSTM(128,input_shape=x_train.shape[1:],activation='tanh',return_sequences=True)\n",
    "model.add(couche_1)\n",
    "\n",
    "couche_2=Dropout(0.2)\n",
    "model.add(couche_2)\n",
    "\n",
    "couche_3=BatchNormalization()\n",
    "model.add(couche_3)\n",
    "\n",
    "couche_4=LSTM(64,activation='tanh',return_sequences=True)\n",
    "model.add(couche_4)\n",
    "\n",
    "couche_5=Dropout(0.1)\n",
    "model.add(couche_5)\n",
    "\n",
    "couche_12=Dense(2, activation='softmax')\n",
    "model.add(couche_12)\n",
    "\n",
    "\n",
    "#compile  !\n",
    "opt=RMSprop(lr=0.001)\n",
    "'''tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "couche_10=Dense(32,activation='relu')\n",
    "model.add(couche_10)\n",
    "\n",
    "couche_11=Dropout(0.2)\n",
    "model.add(couche_11)\n",
    "\n",
    "gvs = opt.compute_gradients(cost)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = opt.apply_gradients(capped_gvs)\n",
    "opt.apply_gradients(capped_gvs)'''\n",
    "\n",
    "matrics=['accuracy']\n",
    "loss='sparse_categorical_crossentropy'\n",
    "              #'sparse_categorical_crossentropy'\n",
    "model.compile(loss=loss,\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "#pour le tensorboard  : \n",
    "tensorboard=TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "#pour le ModelCheckpoint\n",
    "              \n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "#let's train the data ! \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps j ai executer le modele avec les caractéristiques suivantes : 60-SEQ-3-PRED-1550310126\n",
    "    EPOCHs= 10 \n",
    "    BATCH=64 \n",
    "    optimizer = adam ! \n",
    "    3 couches LSTM de 128 noeuds chaqunne avec une fonction d'activation = relu \n",
    "    1 couche dense \n",
    "    loss='sparse_categorical_crossentropy'\n",
    "2éme : 60-SEQ-3-PRED-1550325231\n",
    "   Epochs=5 \n",
    "   BATCH=32\n",
    "   optimisier = adam \n",
    "   3 couches LSTM avec tan h comme activation et 128 64 16 nombre de noeuds \n",
    "   loss='sparse_categorical_crossentropy'\n",
    "   1 seule couche dense\n",
    "3éme : 60-SEQ-3-PRED-1550332261\n",
    " Epochs=5 \n",
    "   BATCH=32\n",
    "   optimisier = adam \n",
    "   3 couches LSTM avec tan h comme activation et 128 64 16 nombre de noeuds \n",
    "   loss='sparse_categorical_crossentropy'\n",
    "   2  couches dense\n",
    "4éme : c 'est la 3 éme avec epochs=12 avec dérniére lstm 32 noeud au lieu de 16 \n",
    "\n",
    "mazal hadi !5éme : \n",
    "Epochs=5 \n",
    "   BATCH=32\n",
    "   optimisier = adam \n",
    "   3 couches LSTM avec tan h comme activation et 128  nombre de noeuds \n",
    "   loss=binary-crossentropy\n",
    "   1 couche dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_val, y_val)\n",
    " #  , callbacks=[tensorboard,checkpoint]\n",
    ")            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model\n",
    "score = model.evaluate(x_val,y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ i for i in range(1,4)]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.expand_dims(a, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2],[2,3],[1,3,8],[4,9]]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as ny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.array([[1,2,8],[2,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.random.randint(12,45,size=8)\n",
    "p=np.array([p,z])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[::2,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(z))\n",
    "print(np.max(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.append(z,[1,3,5,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=np.array([1,2,3])\n",
    "y=np.array([9,0,8])\n",
    "z@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x= [1,2,4]\n",
    "y=[4,8,9]\n",
    "plt.plot(x,y,'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
